{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982bde2c",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-05-22T03:01:54.789689Z",
     "iopub.status.busy": "2025-05-22T03:01:54.789347Z",
     "iopub.status.idle": "2025-05-22T03:02:13.088442Z",
     "shell.execute_reply": "2025-05-22T03:02:13.087563Z"
    },
    "papermill": {
     "duration": 18.308957,
     "end_time": "2025-05-22T03:02:13.090048",
     "exception": false,
     "start_time": "2025-05-22T03:01:54.781091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d610466c",
   "metadata": {
    "papermill": {
     "duration": 0.021603,
     "end_time": "2025-05-22T03:02:13.135773",
     "exception": false,
     "start_time": "2025-05-22T03:02:13.114170",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Environments\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd77161",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:02:13.181398Z",
     "iopub.status.busy": "2025-05-22T03:02:13.180978Z",
     "iopub.status.idle": "2025-05-22T03:02:13.309803Z",
     "shell.execute_reply": "2025-05-22T03:02:13.308690Z"
    },
    "papermill": {
     "duration": 0.153288,
     "end_time": "2025-05-22T03:02:13.311438",
     "exception": false,
     "start_time": "2025-05-22T03:02:13.158150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%ls /kaggle/input/boltz-dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07ee4cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:02:13.358191Z",
     "iopub.status.busy": "2025-05-22T03:02:13.357852Z",
     "iopub.status.idle": "2025-05-22T03:02:22.362912Z",
     "shell.execute_reply": "2025-05-22T03:02:22.361956Z"
    },
    "papermill": {
     "duration": 9.030431,
     "end_time": "2025-05-22T03:02:22.365132",
     "exception": false,
     "start_time": "2025-05-22T03:02:13.334701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --no-index /kaggle/input/boltz-dependencies/*whl --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f429c4b2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:02:22.412822Z",
     "iopub.status.busy": "2025-05-22T03:02:22.412530Z",
     "iopub.status.idle": "2025-05-22T03:02:23.656844Z",
     "shell.execute_reply": "2025-05-22T03:02:23.655790Z"
    },
    "papermill": {
     "duration": 1.269546,
     "end_time": "2025-05-22T03:02:23.658596",
     "exception": false,
     "start_time": "2025-05-22T03:02:22.389050",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --no-index /kaggle/input/fairscale-0413/*whl --no-deps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d38f5d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:02:23.706197Z",
     "iopub.status.busy": "2025-05-22T03:02:23.705857Z",
     "iopub.status.idle": "2025-05-22T03:02:25.832422Z",
     "shell.execute_reply": "2025-05-22T03:02:25.831542Z"
    },
    "papermill": {
     "duration": 2.151653,
     "end_time": "2025-05-22T03:02:25.834368",
     "exception": false,
     "start_time": "2025-05-22T03:02:23.682715",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install --no-index /kaggle/input/biopython/*whl --no-deps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ebb208",
   "metadata": {
    "papermill": {
     "duration": 0.022673,
     "end_time": "2025-05-22T03:02:25.880351",
     "exception": false,
     "start_time": "2025-05-22T03:02:25.857678",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccb1d3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:02:25.926771Z",
     "iopub.status.busy": "2025-05-22T03:02:25.926392Z",
     "iopub.status.idle": "2025-05-22T03:02:25.931901Z",
     "shell.execute_reply": "2025-05-22T03:02:25.930999Z"
    },
    "papermill": {
     "duration": 0.029549,
     "end_time": "2025-05-22T03:02:25.933326",
     "exception": false,
     "start_time": "2025-05-22T03:02:25.903777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cd /kaggle/working/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f74ce22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:02:25.978425Z",
     "iopub.status.busy": "2025-05-22T03:02:25.978149Z",
     "iopub.status.idle": "2025-05-22T03:02:26.213995Z",
     "shell.execute_reply": "2025-05-22T03:02:26.212671Z"
    },
    "papermill": {
     "duration": 0.260642,
     "end_time": "2025-05-22T03:02:26.215936",
     "exception": false,
     "start_time": "2025-05-22T03:02:25.955294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%mkdir inputs_prediction\n",
    "%mkdir outputs_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90e1e9e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:02:26.264116Z",
     "iopub.status.busy": "2025-05-22T03:02:26.263820Z",
     "iopub.status.idle": "2025-05-22T03:02:27.066834Z",
     "shell.execute_reply": "2025-05-22T03:02:27.065196Z"
    },
    "papermill": {
     "duration": 0.829677,
     "end_time": "2025-05-22T03:02:27.069906",
     "exception": false,
     "start_time": "2025-05-22T03:02:26.240229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%cp -rf /kaggle/input/rna-prediction-boltz/boltz/src/boltz ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d55fd7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:02:27.134440Z",
     "iopub.status.busy": "2025-05-22T03:02:27.134113Z",
     "iopub.status.idle": "2025-05-22T03:02:27.254251Z",
     "shell.execute_reply": "2025-05-22T03:02:27.253040Z"
    },
    "papermill": {
     "duration": 0.154145,
     "end_time": "2025-05-22T03:02:27.255849",
     "exception": false,
     "start_time": "2025-05-22T03:02:27.101704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%ls boltz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12908a14",
   "metadata": {
    "papermill": {
     "duration": 0.022704,
     "end_time": "2025-05-22T03:02:27.303511",
     "exception": false,
     "start_time": "2025-05-22T03:02:27.280807",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Write file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8ee296",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:02:27.350279Z",
     "iopub.status.busy": "2025-05-22T03:02:27.349794Z",
     "iopub.status.idle": "2025-05-22T03:02:27.358610Z",
     "shell.execute_reply": "2025-05-22T03:02:27.357864Z"
    },
    "papermill": {
     "duration": 0.03401,
     "end_time": "2025-05-22T03:02:27.359907",
     "exception": false,
     "start_time": "2025-05-22T03:02:27.325897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing inference.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile inference.py\n",
    "import pickle\n",
    "import urllib.request\n",
    "from dataclasses import asdict, dataclass\n",
    "from pathlib import Path\n",
    "from typing import Literal, Optional\n",
    "import click\n",
    "import torch\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.strategies import DDPStrategy\n",
    "from pytorch_lightning.utilities import rank_zero_only\n",
    "from tqdm import tqdm\n",
    "from boltz.data import const\n",
    "from boltz.data.module.inference import BoltzInferenceDataModule\n",
    "from boltz.data.msa.mmseqs2 import run_mmseqs2\n",
    "from boltz.data.parse.a3m import parse_a3m\n",
    "from boltz.data.parse.csv import parse_csv\n",
    "from boltz.data.parse.fasta import parse_fasta\n",
    "from boltz.data.parse.yaml import parse_yaml\n",
    "from boltz.data.types import MSA, Manifest, Record\n",
    "from boltz.data.write.writer import BoltzWriter\n",
    "from boltz.model.model import Boltz1\n",
    "\n",
    "CCD_URL = \"https://huggingface.co/boltz-community/boltz-1/resolve/main/ccd.pkl\"\n",
    "MODEL_URL = \"https://huggingface.co/boltz-community/boltz-1/resolve/main/boltz1_conf.ckpt\"\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class InferenceArtifacts:\n",
    "    \"\"\"Container for processed/ready-to-infer paths.\"\"\"\n",
    "    manifest: Manifest\n",
    "    targets_dir: Path\n",
    "    msa_dir: Path\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class SamplerHyperparams:\n",
    "    \"\"\"Diffusion/sampling hyperparameters.\"\"\"\n",
    "    gamma_0: float = 0.605\n",
    "    gamma_min: float = 1.107\n",
    "    noise_scale: float = 0.901\n",
    "    rho: float = 8\n",
    "    step_scale: float = 1.638\n",
    "    sigma_min: float = 0.0004\n",
    "    sigma_max: float = 160.0\n",
    "    sigma_data: float = 16.0\n",
    "    P_mean: float = -1.2\n",
    "    P_std: float = 1.5\n",
    "    coordinate_augmentation: bool = True\n",
    "    alignment_reverse_diff: bool = True\n",
    "    synchronize_sigmas: bool = True\n",
    "    use_inference_model_cache: bool = True\n",
    "\n",
    "\n",
    "@rank_zero_only\n",
    "def ensure_artifacts_downloaded(cache_dir: Path) -> None:\n",
    "    \"\"\"Fetch CCD dict and model weights into cache_dir if missing.\"\"\"\n",
    "    ccd_path = cache_dir / \"ccd.pkl\"\n",
    "    if not ccd_path.exists():\n",
    "        click.echo(\n",
    "            f\"Downloading the CCD dictionary to {ccd_path}. \"\n",
    "            \"You may change the cache directory with the --cache flag.\"\n",
    "        )\n",
    "        urllib.request.urlretrieve(CCD_URL, str(ccd_path))  # noqa: S310\n",
    "\n",
    "    model_ckpt = cache_dir / \"boltz1_conf.ckpt\"\n",
    "    if not model_ckpt.exists():\n",
    "        click.echo(\n",
    "            f\"Downloading the model weights to {model_ckpt}. \"\n",
    "            \"You may change the cache directory with the --cache flag.\"\n",
    "        )\n",
    "        urllib.request.urlretrieve(MODEL_URL, str(model_ckpt))  # noqa: S310\n",
    "\n",
    "\n",
    "def resolve_and_filter_inputs(\n",
    "    input_path: Path,\n",
    "    output_dir: Path,\n",
    "    override_existing: bool = False,\n",
    ") -> list[Path]:\n",
    "    \"\"\"Expand inputs, validate types, and skip already-predicted targets.\"\"\"\n",
    "    click.echo(\"Checking input data.\")\n",
    "\n",
    "    # Expand directory to files or wrap single file\n",
    "    if input_path.is_dir():\n",
    "        candidates: list[Path] = list(input_path.glob(\"*\"))\n",
    "        filtered: list[Path] = []\n",
    "        for p in candidates:\n",
    "            if p.suffix in (\".fa\", \".fas\", \".fasta\", \".yml\", \".yaml\"):\n",
    "                filtered.append(p)\n",
    "            elif p.is_dir():\n",
    "                raise RuntimeError(f\"Found directory {p} instead of .fasta or .yaml.\")\n",
    "            else:\n",
    "                raise RuntimeError(\n",
    "                    f\"Unable to parse filetype {p.suffix}, \"\n",
    "                    \"please provide a .fasta or .yaml file.\"\n",
    "                )\n",
    "        paths = filtered\n",
    "    else:\n",
    "        paths = [input_path]\n",
    "\n",
    "    # Skip those with existing predictions unless override\n",
    "    existing_pred_dirs = (output_dir / \"predictions\").rglob(\"*\")\n",
    "    existing_ids = {e.name for e in existing_pred_dirs if e.is_dir()}\n",
    "\n",
    "    if existing_ids and not override_existing:\n",
    "        pruned = [p for p in paths if p.stem not in existing_ids]\n",
    "        num_skipped = len(paths) - len(pruned)\n",
    "        click.echo(\n",
    "            f\"Found some existing predictions ({num_skipped}), \"\n",
    "            \"skipping and running only the missing ones. \"\n",
    "            \"Use --override to recompute.\"\n",
    "        )\n",
    "        paths = pruned\n",
    "    elif existing_ids and override_existing:\n",
    "        click.echo(\"Found existing predictions, will override.\")\n",
    "\n",
    "    return paths\n",
    "\n",
    "\n",
    "def build_msa_alignments(\n",
    "    sequences_by_entity: dict[str, str],\n",
    "    target_id: str,\n",
    "    msa_raw_dir: Path,\n",
    "    msa_server_url: str,\n",
    "    msa_pairing_strategy: str,\n",
    ") -> None:\n",
    "    \"\"\"Create paired/unpaired MSAs via MMSeqs2 and save CSVs.\"\"\"\n",
    "    if len(sequences_by_entity) > 1:\n",
    "        paired_msas = run_mmseqs2(\n",
    "            list(sequences_by_entity.values()),\n",
    "            msa_raw_dir / f\"{target_id}_paired_tmp\",\n",
    "            use_env=True,\n",
    "            use_pairing=True,\n",
    "            host_url=msa_server_url,\n",
    "            pairing_strategy=msa_pairing_strategy,\n",
    "        )\n",
    "    else:\n",
    "        paired_msas = [\"\"] * len(sequences_by_entity)\n",
    "\n",
    "    unpaired_msas = run_mmseqs2(\n",
    "        list(sequences_by_entity.values()),\n",
    "        msa_raw_dir / f\"{target_id}_unpaired_tmp\",\n",
    "        use_env=True,\n",
    "        use_pairing=False,\n",
    "        host_url=msa_server_url,\n",
    "        pairing_strategy=msa_pairing_strategy,\n",
    "    )\n",
    "\n",
    "    for idx, entity_name in enumerate(sequences_by_entity):\n",
    "        # Paired block\n",
    "        paired = paired_msas[idx].strip().splitlines()\n",
    "        paired = paired[1::2]  # strip headers\n",
    "        paired = paired[: const.max_paired_seqs]\n",
    "\n",
    "        keep_keys = [i for i, s in enumerate(paired) if s != \"-\" * len(s)]\n",
    "        paired = [s for s in paired if s != \"-\" * len(s)]\n",
    "\n",
    "        # Unpaired block\n",
    "        unpaired = unpaired_msas[idx].strip().splitlines()\n",
    "        unpaired = unpaired[1::2]\n",
    "        unpaired = unpaired[: (const.max_msa_seqs - len(paired))]\n",
    "        if paired:\n",
    "            unpaired = unpaired[1:]  # query already present\n",
    "\n",
    "        # Merge and write csv\n",
    "        seqs = paired + unpaired\n",
    "        keys = keep_keys + [-1] * len(unpaired)\n",
    "\n",
    "        csv_lines = [\"key,sequence\"] + [f\"{k},{s}\" for k, s in zip(keys, seqs)]\n",
    "        (msa_raw_dir / f\"{entity_name}.csv\").write_text(\"\\n\".join(csv_lines))\n",
    "\n",
    "\n",
    "@rank_zero_only\n",
    "def preprocess_dataset(  # noqa: C901, PLR0912, PLR0915\n",
    "    inputs: list[Path],\n",
    "    output_dir: Path,\n",
    "    ccd_pickle: Path,\n",
    "    msa_server_url: str,\n",
    "    msa_pairing_strategy: str,\n",
    "    max_msa_seqs: int = 4096,\n",
    "    allow_msa_server: bool = False,\n",
    ") -> None:\n",
    "    \"\"\"Parse inputs, generate/convert MSAs, dump structures + manifest.\"\"\"\n",
    "    click.echo(\"Processing input data.\")\n",
    "    prior_records: Optional[list[Record]] = None\n",
    "\n",
    "    # Reuse/update existing manifest if present\n",
    "    manifest_path = output_dir / \"processed\" / \"manifest.json\"\n",
    "    if manifest_path.exists():\n",
    "        click.echo(f\"Found a manifest file at output directory: {output_dir}\")\n",
    "        manifest: Manifest = Manifest.load(manifest_path)\n",
    "        requested_ids = [p.stem for p in inputs]\n",
    "        found_pairs = [\n",
    "            (rec, rec.id) for rec in manifest.records if rec.id in requested_ids\n",
    "        ]\n",
    "        if found_pairs:\n",
    "            prior_records, already = zip(*found_pairs)\n",
    "            prior_records = list(prior_records)\n",
    "            missing_count = len(requested_ids) - len(already)\n",
    "            if missing_count == 0:\n",
    "                click.echo(\"All examples in data are processed. Updating the manifest\")\n",
    "                Manifest(prior_records).dump(manifest_path)\n",
    "                return\n",
    "            click.echo(f\"{missing_count} missing ids. Preprocessing these ids\")\n",
    "            missing_ids = set(requested_ids).difference(set(already))\n",
    "            inputs = [p for p in inputs if p.stem in missing_ids]\n",
    "\n",
    "    # Directories\n",
    "    msa_raw_dir = output_dir / \"msa\"\n",
    "    struct_dir = output_dir / \"processed\" / \"structures\"\n",
    "    msa_proc_dir = output_dir / \"processed\" / \"msa\"\n",
    "    preds_dir = output_dir / \"predictions\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    msa_raw_dir.mkdir(parents=True, exist_ok=True)\n",
    "    struct_dir.mkdir(parents=True, exist_ok=True)\n",
    "    msa_proc_dir.mkdir(parents=True, exist_ok=True)\n",
    "    preds_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Load CCD\n",
    "    with ccd_pickle.open(\"rb\") as fh:\n",
    "        ccd = pickle.load(fh)  # noqa: S301\n",
    "\n",
    "    if prior_records is not None:\n",
    "        click.echo(f\"Found {len(prior_records)} records. Adding them to records\")\n",
    "\n",
    "    records: list[Record] = prior_records if prior_records is not None else []\n",
    "    for path in tqdm(inputs):\n",
    "        try:\n",
    "            # Parse input target\n",
    "            if path.suffix in (\".fa\", \".fas\", \".fasta\"):\n",
    "                parsed = parse_fasta(path, ccd)\n",
    "            elif path.suffix in (\".yml\", \".yaml\"):\n",
    "                parsed = parse_yaml(path, ccd)\n",
    "            elif path.is_dir():\n",
    "                raise RuntimeError(f\"Found directory {path} instead of .fasta or .yaml, skipping.\")\n",
    "            else:\n",
    "                raise RuntimeError(\n",
    "                    f\"Unable to parse filetype {path.suffix}, please provide a .fasta or .yaml file.\"\n",
    "                )\n",
    "\n",
    "            target_id = parsed.record.id\n",
    "\n",
    "            # Determine which chains need MSA generation\n",
    "            to_generate: dict[str, str] = {}\n",
    "            protein_type = const.chain_type_ids[\"PROTEIN\"]\n",
    "            for ch in parsed.record.chains:\n",
    "                if (ch.mol_type == protein_type) and (ch.msa_id == 0):\n",
    "                    entity_id = ch.entity_id\n",
    "                    msa_stub = f\"{target_id}_{entity_id}\"\n",
    "                    to_generate[msa_stub] = parsed.sequences[entity_id]\n",
    "                    ch.msa_id = msa_raw_dir / f\"{msa_stub}.csv\"\n",
    "                elif ch.msa_id == 0:\n",
    "                    ch.msa_id = -1  # unsupported for non-protein\n",
    "\n",
    "            if to_generate and not allow_msa_server:\n",
    "                raise RuntimeError(\"Missing MSAs and --use_msa_server flag not set.\")\n",
    "\n",
    "            if to_generate:\n",
    "                click.echo(f\"Generating MSA for {path} with {len(to_generate)} protein entities.\")\n",
    "                build_msa_alignments(\n",
    "                    sequences_by_entity=to_generate,\n",
    "                    target_id=target_id,\n",
    "                    msa_raw_dir=msa_raw_dir,\n",
    "                    msa_server_url=msa_server_url,\n",
    "                    msa_pairing_strategy=msa_pairing_strategy,\n",
    "                )\n",
    "\n",
    "            # Convert raw MSAs to processed NPZs\n",
    "            distinct_msas = sorted({c.msa_id for c in parsed.record.chains if c.msa_id != -1})\n",
    "            msa_id_map: dict[Path | str, str] = {}\n",
    "            for idx, raw_id in enumerate(distinct_msas):\n",
    "                raw_path = Path(raw_id)\n",
    "                if not raw_path.exists():\n",
    "                    raise FileNotFoundError(f\"MSA file {raw_path} not found.\")\n",
    "\n",
    "                npz_out = msa_proc_dir / f\"{target_id}_{idx}.npz\"\n",
    "                msa_id_map[raw_id] = f\"{target_id}_{idx}\"\n",
    "                if not npz_out.exists():\n",
    "                    if raw_path.suffix == \".a3m\":\n",
    "                        msa_obj: MSA = parse_a3m(raw_path, taxonomy=None, max_seqs=max_msa_seqs)\n",
    "                    elif raw_path.suffix == \".csv\":\n",
    "                        msa_obj: MSA = parse_csv(raw_path, max_seqs=max_msa_seqs)\n",
    "                    else:\n",
    "                        raise RuntimeError(f\"MSA file {raw_path} not supported, only a3m or csv.\")\n",
    "                    msa_obj.dump(npz_out)\n",
    "\n",
    "            # Repoint chains to processed MSA ids\n",
    "            for ch in parsed.record.chains:\n",
    "                if (ch.msa_id != -1) and (ch.msa_id in msa_id_map):\n",
    "                    ch.msa_id = msa_id_map[ch.msa_id]\n",
    "\n",
    "            records.append(parsed.record)\n",
    "\n",
    "            # Dump structure\n",
    "            (struct_dir / f\"{parsed.record.id}.npz\").parent.mkdir(parents=True, exist_ok=True)\n",
    "            parsed.structure.dump(struct_dir / f\"{parsed.record.id}.npz\")\n",
    "\n",
    "        except Exception as exc:\n",
    "            if len(inputs) > 1:\n",
    "                print(f\"Failed to process {path}. Skipping. Error: {exc}.\")\n",
    "            else:\n",
    "                raise exc\n",
    "\n",
    "    Manifest(records).dump(output_dir / \"processed\" / \"manifest.json\")\n",
    "\n",
    "\n",
    "def run_inference(\n",
    "    data: str,\n",
    "    out_dir: str,\n",
    "    cache: str = \"~/.boltz\",\n",
    "    checkpoint: Optional[str] = None,\n",
    "    devices: int = 1,\n",
    "    accelerator: str = \"gpu\",\n",
    "    recycling_steps: int = 3,\n",
    "    sampling_steps: int = 200,\n",
    "    diffusion_samples: int = 10,\n",
    "    step_scale: float = 1.638,\n",
    "    write_full_pae: bool = False,\n",
    "    write_full_pde: bool = False,\n",
    "    output_format: Literal[\"pdb\", \"mmcif\"] = \"mmcif\",\n",
    "    num_workers: int = 2,\n",
    "    override: bool = False,\n",
    "    seed: Optional[int] = None,\n",
    "    use_msa_server: bool = False,\n",
    "    msa_server_url: str = \"https://api.colabfold.com\",\n",
    "    msa_pairing_strategy: str = \"greedy\",\n",
    ") -> None:\n",
    "    \"\"\"Run Boltz-1 predictions with refactored names.\"\"\"\n",
    "    if accelerator == \"cpu\":\n",
    "        click.echo(\"Running on CPU, this will be slow. Consider using a GPU.\")\n",
    "\n",
    "    torch.set_grad_enabled(False)\n",
    "    torch.set_float32_matmul_precision(\"highest\")\n",
    "\n",
    "    if seed is not None:\n",
    "        seed_everything(int(seed))\n",
    "\n",
    "    cache_dir = Path(cache).expanduser()\n",
    "    cache_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    input_path = Path(data).expanduser()\n",
    "    output_dir = Path(out_dir).expanduser() / f\"boltz_results_{input_path.stem}\"\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    ensure_artifacts_downloaded(cache_dir)\n",
    "\n",
    "    # Validate/collect inputs\n",
    "    input_paths = resolve_and_filter_inputs(input_path, output_dir, override_existing=override)\n",
    "    if not input_paths:\n",
    "        click.echo(\"No predictions to run, exiting.\")\n",
    "        return\n",
    "\n",
    "    # Trainer strategy\n",
    "    strategy: str | DDPStrategy = \"auto\"\n",
    "    if (isinstance(devices, int) and devices > 1) or (isinstance(devices, list) and len(devices) > 1):\n",
    "        strategy = DDPStrategy()\n",
    "        if len(input_paths) < (devices if isinstance(devices, int) else len(devices)):\n",
    "            raise ValueError(\"Requested more devices than predictions.\")\n",
    "\n",
    "    plural = \"s\" if len(input_paths) > 1 else \"\"\n",
    "    click.echo(f\"Running predictions for {len(input_paths)} structure{plural}\")\n",
    "\n",
    "    # Preprocess\n",
    "    ccd_pickle = cache_dir / \"ccd.pkl\"\n",
    "    preprocess_dataset(\n",
    "        inputs=input_paths,\n",
    "        output_dir=output_dir,\n",
    "        ccd_pickle=ccd_pickle,\n",
    "        allow_msa_server=use_msa_server,\n",
    "        msa_server_url=msa_server_url,\n",
    "        msa_pairing_strategy=msa_pairing_strategy,\n",
    "    )\n",
    "\n",
    "    # Load processed artifacts\n",
    "    processed_root = output_dir / \"processed\"\n",
    "    artifacts = InferenceArtifacts(\n",
    "        manifest=Manifest.load(processed_root / \"manifest.json\"),\n",
    "        targets_dir=processed_root / \"structures\",\n",
    "        msa_dir=processed_root / \"msa\",\n",
    "    )\n",
    "\n",
    "    # Data module\n",
    "    dm = BoltzInferenceDataModule(\n",
    "        manifest=artifacts.manifest,\n",
    "        target_dir=artifacts.targets_dir,\n",
    "        msa_dir=artifacts.msa_dir,\n",
    "        num_workers=num_workers,\n",
    "    )\n",
    "\n",
    "    # Model\n",
    "    ckpt_path = Path(checkpoint) if checkpoint is not None else (cache_dir / \"boltz1_conf.ckpt\")\n",
    "    predict_args = {\n",
    "        \"recycling_steps\": recycling_steps,\n",
    "        \"sampling_steps\": sampling_steps,\n",
    "        \"diffusion_samples\": diffusion_samples,\n",
    "        \"write_confidence_summary\": True,\n",
    "        \"write_full_pae\": write_full_pae,\n",
    "        \"write_full_pde\": write_full_pde,\n",
    "    }\n",
    "    sampler_params = SamplerHyperparams()\n",
    "    sampler_params.step_scale = step_scale\n",
    "    model: Boltz1 = Boltz1.load_from_checkpoint(\n",
    "        ckpt_path,\n",
    "        strict=True,\n",
    "        predict_args=predict_args,\n",
    "        map_location=\"cpu\",\n",
    "        diffusion_process_args=asdict(sampler_params),\n",
    "        ema=False,\n",
    "    )\n",
    "    model.eval()\n",
    "\n",
    "    writer = BoltzWriter(\n",
    "        data_dir=artifacts.targets_dir,\n",
    "        output_dir=output_dir / \"predictions\",\n",
    "        output_format=output_format,\n",
    "    )\n",
    "\n",
    "    trainer = Trainer(\n",
    "        default_root_dir=output_dir,\n",
    "        strategy=strategy,\n",
    "        callbacks=[writer],\n",
    "        accelerator=accelerator,\n",
    "        devices=devices,\n",
    "        precision=32,\n",
    "    )\n",
    "\n",
    "    trainer.predict(model, datamodule=dm, return_predictions=False)\n",
    "\n",
    "\n",
    "# Backwards-compatible wrapper (optional): keep old entrypoint name working.\n",
    "def predict(*args, **kwargs):\n",
    "    \"\"\"Deprecated alias for run_inference (kept for compatibility).\"\"\"\n",
    "    return run_inference(*args, **kwargs)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    run_inference(\n",
    "        data=\"./inputs_prediction\",\n",
    "        out_dir=\"./outputs_prediction\",\n",
    "        cache=\"/kaggle/input/rna-prediction-boltz/\",\n",
    "        diffusion_samples=10,\n",
    "        seed=42,\n",
    "        override=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cccb0b0",
   "metadata": {
    "papermill": {
     "duration": 0.023434,
     "end_time": "2025-05-22T03:02:27.406751",
     "exception": false,
     "start_time": "2025-05-22T03:02:27.383317",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Prepare inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece86e57",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:02:27.453800Z",
     "iopub.status.busy": "2025-05-22T03:02:27.453450Z",
     "iopub.status.idle": "2025-05-22T03:02:27.477138Z",
     "shell.execute_reply": "2025-05-22T03:02:27.476484Z"
    },
    "papermill": {
     "duration": 0.048357,
     "end_time": "2025-05-22T03:02:27.478520",
     "exception": false,
     "start_time": "2025-05-22T03:02:27.430163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def generate_yaml_inputs(\n",
    "    csv_path: str | Path,\n",
    "    output_dir: str | Path = \"/kaggle/working/inputs_prediction\",\n",
    ") -> list[Path]:\n",
    "    \"\"\"\n",
    "    Read a CSV of targets and sequences and write one YAML file per target.\n",
    "\n",
    "    Expected CSV columns: 'target_id', 'sequence'\n",
    "    \"\"\"\n",
    "    csv_path = Path(csv_path)\n",
    "    output_dir = Path(output_dir)\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    df_sequences = pd.read_csv(csv_path)\n",
    "    # Optional peek\n",
    "    display(df_sequences.head())\n",
    "\n",
    "    target_ids = df_sequences[\"target_id\"].tolist()\n",
    "    rna_seqs = df_sequences[\"sequence\"].tolist()\n",
    "\n",
    "    written_files: list[Path] = []\n",
    "    for target_id, rna_seq in zip(target_ids, rna_seqs):\n",
    "        yaml_text = (\n",
    "            \"constraints: []\\n\"\n",
    "            \"sequences:\\n\"\n",
    "            \"- rna:\\n\"\n",
    "            \"    id:\\n\"\n",
    "            \"    - A1\\n\"\n",
    "            f\"    sequence: {rna_seq}\"\n",
    "        )\n",
    "        yaml_path = output_dir / f\"{target_id}.yaml\"\n",
    "        yaml_path.write_text(yaml_text)\n",
    "        written_files.append(yaml_path)\n",
    "\n",
    "    return written_files\n",
    "\n",
    "\n",
    "# Run it:\n",
    "_ = generate_yaml_inputs(\n",
    "    csv_path=\"/kaggle/input/stanford-rna-3d-folding/test_sequences.csv\",\n",
    "    output_dir=\"/kaggle/working/inputs_prediction\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79503c95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:02:27.524086Z",
     "iopub.status.busy": "2025-05-22T03:02:27.523802Z",
     "iopub.status.idle": "2025-05-22T03:02:27.643814Z",
     "shell.execute_reply": "2025-05-22T03:02:27.642551Z"
    },
    "papermill": {
     "duration": 0.144506,
     "end_time": "2025-05-22T03:02:27.645545",
     "exception": false,
     "start_time": "2025-05-22T03:02:27.501039",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1107.yaml  R1116.yaml    R1126.yaml  R1136.yaml  R1149.yaml  R1189.yaml\r\n",
      "R1108.yaml  R1117v2.yaml  R1128.yaml  R1138.yaml  R1156.yaml  R1190.yaml\r\n"
     ]
    }
   ],
   "source": [
    "%ls inputs_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edf81b7f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:02:27.692319Z",
     "iopub.status.busy": "2025-05-22T03:02:27.691972Z",
     "iopub.status.idle": "2025-05-22T03:02:27.811334Z",
     "shell.execute_reply": "2025-05-22T03:02:27.810346Z"
    },
    "papermill": {
     "duration": 0.144328,
     "end_time": "2025-05-22T03:02:27.813071",
     "exception": false,
     "start_time": "2025-05-22T03:02:27.668743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%ls outputs_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda1b7bc",
   "metadata": {
    "papermill": {
     "duration": 0.022336,
     "end_time": "2025-05-22T03:02:27.859258",
     "exception": false,
     "start_time": "2025-05-22T03:02:27.836922",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Exec inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e24f8e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:02:31.807309Z",
     "iopub.status.busy": "2025-05-22T03:02:31.807010Z",
     "iopub.status.idle": "2025-05-22T03:33:32.969992Z",
     "shell.execute_reply": "2025-05-22T03:33:32.969238Z"
    },
    "papermill": {
     "duration": 1861.187713,
     "end_time": "2025-05-22T03:33:32.971976",
     "exception": false,
     "start_time": "2025-05-22T03:02:31.784263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import logging\n",
    "import subprocess\n",
    "from pathlib import Path\n",
    "import torch\n",
    "\n",
    "def clear_cuda_cache() -> None:\n",
    "    \"\"\"Free up GPU memory before running inference.\"\"\"\n",
    "    try:\n",
    "        torch.cuda.empty_cache()\n",
    "    except Exception:\n",
    "        pass\n",
    "    gc.collect()\n",
    "\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s | %(message)s\")\n",
    "logger = logging.getLogger(\"inference_exec\")\n",
    "\n",
    "def _tail(text: str, n: int = 40) -> str:\n",
    "    lines = text.strip().splitlines()\n",
    "    return \"\\n\".join(lines[-n:]) if lines else \"\"\n",
    "\n",
    "def run_inference_script(\n",
    "    python_bin: str = \"python\",\n",
    "    script_path: str | Path = \"inference.py\",\n",
    "    extra_args: list[str] | None = None,\n",
    "    workdir: str | Path | None = None,\n",
    ") -> subprocess.CompletedProcess:\n",
    "    \"\"\"\n",
    "    Run the inference script as a subprocess and return the CompletedProcess.\n",
    "    Prints a short, useful log summary (return code + tails of stdout/stderr).\n",
    "    \"\"\"\n",
    "    cmd = [python_bin, str(script_path)]\n",
    "    if extra_args:\n",
    "        cmd += list(extra_args)\n",
    "\n",
    "    logger.info(f\"Launching: {' '.join(cmd)}\")\n",
    "    result = subprocess.run(\n",
    "        cmd,\n",
    "        capture_output=True,\n",
    "        text=True,\n",
    "        cwd=str(workdir) if workdir else None,\n",
    "    )\n",
    "\n",
    "    logger.info(f\"Return code: {result.returncode}\")\n",
    "    if result.stdout:\n",
    "        logger.info(\"STDOUT (tail):\\n\" + _tail(result.stdout))\n",
    "    if result.stderr:\n",
    "        # stderr can contain non-fatal warnings; keep as WARNING not ERROR by default\n",
    "        logger.warning(\"STDERR (tail):\\n\" + _tail(result.stderr))\n",
    "    return result\n",
    "\n",
    "clear_cuda_cache()\n",
    "result = run_inference_script(\n",
    "    python_bin=\"python\",\n",
    "    script_path=\"inference.py\",\n",
    "    # If your inference.py takes CLI args, add them here:\n",
    "    extra_args=None,\n",
    "    workdir=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a322a9e1",
   "metadata": {
    "papermill": {
     "duration": 0.022056,
     "end_time": "2025-05-22T03:33:33.018905",
     "exception": false,
     "start_time": "2025-05-22T03:33:32.996849",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Read RNA files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e393af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:33:33.063958Z",
     "iopub.status.busy": "2025-05-22T03:33:33.063713Z",
     "iopub.status.idle": "2025-05-22T03:33:33.068322Z",
     "shell.execute_reply": "2025-05-22T03:33:33.067562Z"
    },
    "papermill": {
     "duration": 0.028763,
     "end_time": "2025-05-22T03:33:33.069620",
     "exception": false,
     "start_time": "2025-05-22T03:33:33.040857",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['python', 'inference.py'], returncode=0, stdout='Checking input data.\\nRunning predictions for 12 structures\\nProcessing input data.\\n\\nPredicting: |          | 0/? [00:00<?, ?it/s]\\nPredicting:   0%|          | 0/12 [00:00<?, ?it/s]\\nPredicting DataLoader 0:   0%|          | 0/12 [00:00<?, ?it/s]\\nPredicting DataLoader 0:   8%|▊         | 1/12 [00:33<06:04,  0.03it/s]\\nPredicting DataLoader 0:  17%|█▋        | 2/12 [04:23<21:56,  0.01it/s]\\nPredicting DataLoader 0:  25%|██▌       | 3/12 [05:12<15:36,  0.01it/s]\\nPredicting DataLoader 0:  33%|███▎      | 4/12 [19:00<38:01,  0.00it/s]\\nPredicting DataLoader 0:  42%|████▏     | 5/12 [19:30<27:18,  0.00it/s]\\nPredicting DataLoader 0:  50%|█████     | 6/12 [20:19<20:19,  0.00it/s]\\nPredicting DataLoader 0:  58%|█████▊    | 7/12 [21:26<15:18,  0.01it/s]\\nPredicting DataLoader 0:  67%|██████▋   | 8/12 [21:42<10:51,  0.01it/s]\\nPredicting DataLoader 0:  75%|███████▌  | 9/12 [25:24<08:28,  0.01it/s]\\nPredicting DataLoader 0:  83%|████████▎ | 10/12 [26:15<05:15,  0.01it/s]\\nPredicting DataLoader 0:  92%|█████████▏| 11/12 [27:12<02:28,  0.01it/s]\\nPredicting DataLoader 0: 100%|██████████| 12/12 [29:11<00:00,  0.01it/s]Number of failed examples: 0\\n\\nPredicting DataLoader 0: 100%|██████████| 12/12 [29:11<00:00,  0.01it/s]\\n', stderr='\\n  0%|          | 0/12 [00:00<?, ?it/s]\\n 17%|█▋        | 2/12 [00:00<00:00, 11.74it/s]\\n 33%|███▎      | 4/12 [00:00<00:01,  7.89it/s]\\n 58%|█████▊    | 7/12 [00:00<00:00, 12.51it/s]\\n 75%|███████▌  | 9/12 [00:00<00:00, 12.96it/s]\\n100%|██████████| 12/12 [00:01<00:00,  9.93it/s]\\n100%|██████████| 12/12 [00:01<00:00, 10.42it/s]\\n2025-05-22 03:04:01.092922: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\\n2025-05-22 03:04:01.326659: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\\n2025-05-22 03:04:01.399498: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\\n')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def summarize_subprocess_result(res: subprocess.CompletedProcess, tail_lines: int = 60):\n",
    "    print(f\"Return code: {res.returncode}\")\n",
    "    print(\"\\n=== STDOUT (last {} lines) ===\".format(tail_lines))\n",
    "    print(_tail(res.stdout, tail_lines))\n",
    "    if res.stderr:\n",
    "        print(\"\\n=== STDERR (last {} lines) ===\".format(tail_lines))\n",
    "        print(_tail(res.stderr, tail_lines))\n",
    "    if res.returncode != 0:\n",
    "        # Surface failure early so the notebook stops before “gather results”\n",
    "        raise RuntimeError(\"Inference script failed (non-zero exit code).\")\n",
    "\n",
    "summarize_subprocess_result(result, tail_lines=80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20118089",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-04T21:51:26.94429Z",
     "iopub.status.busy": "2025-03-04T21:51:26.943982Z",
     "iopub.status.idle": "2025-03-04T21:51:26.949385Z",
     "shell.execute_reply": "2025-03-04T21:51:26.948635Z",
     "shell.execute_reply.started": "2025-03-04T21:51:26.944265Z"
    },
    "papermill": {
     "duration": 0.022532,
     "end_time": "2025-05-22T03:33:33.115721",
     "exception": false,
     "start_time": "2025-05-22T03:33:33.093189",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Gather results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ba9d20",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:33:33.264947Z",
     "iopub.status.busy": "2025-05-22T03:33:33.264674Z",
     "iopub.status.idle": "2025-05-22T03:33:46.129914Z",
     "shell.execute_reply": "2025-05-22T03:33:46.128990Z"
    },
    "papermill": {
     "duration": 12.89022,
     "end_time": "2025-05-22T03:33:46.131370",
     "exception": false,
     "start_time": "2025-05-22T03:33:33.241150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R1128: Used models [0, 1, 2, 3, 4] by confidence\n",
      "R1136: Used models [0, 1, 2, 3, 4] by confidence\n",
      "R1108: Used models [0, 1, 2, 3, 4] by confidence\n",
      "R1126: Used models [0, 1, 2, 3, 4] by confidence\n",
      "R1189: Used models [0, 1, 2, 3, 4] by confidence\n",
      "R1149: Used models [0, 1, 2, 3, 4] by confidence\n",
      "R1107: Used models [0, 1, 2, 3, 4] by confidence\n",
      "R1190: Used models [0, 1, 2, 3, 4] by confidence\n",
      "R1116: Used models [0, 1, 2, 3, 4] by confidence\n",
      "R1117v2: Used models [0, 1, 2, 3, 4] by confidence\n",
      "R1156: Used models [0, 1, 2, 3, 4] by confidence\n",
      "R1138: Used models [0, 1, 2, 3, 4] by confidence\n"
     ]
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from pathlib import Path\n",
    "import json\n",
    "import logging\n",
    "from typing import List, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "from Bio.PDB.MMCIF2Dict import MMCIF2Dict\n",
    "\n",
    "# config \n",
    "PREDICTIONS_ROOT = Path(\"outputs_prediction/boltz_results_inputs_prediction/predictions\")\n",
    "SUBMISSION_TEMPLATE = Path(\"/kaggle/input/stanford-rna-3d-folding/sample_submission.csv\")\n",
    "SUBMISSION_OUT = Path(\"submission.csv\")\n",
    "MAX_MODELS_PER_TARGET = 10\n",
    "TOP_K = 5  # number of predictions to keep per target\n",
    "\n",
    "# logging \n",
    "logging.basicConfig(level=logging.INFO, format=\"%(levelname)s | %(message)s\")\n",
    "log = logging.getLogger(\"gather_results\")\n",
    "\n",
    "#  helpers \n",
    "def read_c1prime_coords_from_cif(cif_path: Path) -> List[Tuple[float, float, float]]:\n",
    "    \"\"\"Extract all C1' coordinates (x,y,z) from a .cif.\"\"\"\n",
    "    mmcif = MMCIF2Dict(str(cif_path))\n",
    "    xs = mmcif[\"_atom_site.Cartn_x\"]\n",
    "    ys = mmcif[\"_atom_site.Cartn_y\"]\n",
    "    zs = mmcif[\"_atom_site.Cartn_z\"]\n",
    "    atom_names = mmcif[\"_atom_site.label_atom_id\"]\n",
    "\n",
    "    coords = [\n",
    "        (float(xs[i]), float(ys[i]), float(zs[i]))\n",
    "        for i, atom in enumerate(atom_names)\n",
    "        if atom == \"C1'\"\n",
    "    ]\n",
    "    if not coords:\n",
    "        raise ValueError(f\"No C1' atoms found in {cif_path}\")\n",
    "    return coords\n",
    "\n",
    "\n",
    "def read_confidence_from_json(json_path: Path) -> float:\n",
    "    \"\"\"Read the global confidence score from confidence_*.json.\"\"\"\n",
    "    with json_path.open(\"r\") as jf:\n",
    "        data = json.load(jf)\n",
    "    if \"confidence_score\" not in data:\n",
    "        raise KeyError(f\"'confidence_score' missing in {json_path}\")\n",
    "    return float(data[\"confidence_score\"])\n",
    "\n",
    "\n",
    "def load_coords_and_confidence(target_id: str, model_idx: int) -> Tuple[list[Tuple[float, float, float]], float]:\n",
    "    \"\"\"\n",
    "    Load C1' coordinates and confidence for a single target/model pair.\n",
    "    Paths follow the Boltz writer convention.\n",
    "    \"\"\"\n",
    "    base = PREDICTIONS_ROOT / target_id\n",
    "    cif_path = base / f\"{target_id}_model_{model_idx}.cif\"\n",
    "    json_path = base / f\"confidence_{target_id}_model_{model_idx}.json\"\n",
    "\n",
    "    if not cif_path.exists():\n",
    "        raise FileNotFoundError(f\"Missing CIF: {cif_path}\")\n",
    "    if not json_path.exists():\n",
    "        raise FileNotFoundError(f\"Missing JSON: {json_path}\")\n",
    "\n",
    "    coords = read_c1prime_coords_from_cif(cif_path)\n",
    "    conf = read_confidence_from_json(json_path)\n",
    "    return coords, conf\n",
    "\n",
    "\n",
    "def fill_submission_for_target(\n",
    "    df_sub: pd.DataFrame,\n",
    "    target_id: str,\n",
    "    best_samples: list[tuple[float, list[tuple[float, float, float]], int]],\n",
    ") -> None:\n",
    "    \"\"\"\n",
    "    For a given target, assign coordinates from top-K samples into x_k,y_k,z_k columns\n",
    "    across all rows where ID starts with the target_id.\n",
    "    \"\"\"\n",
    "    mask = df_sub[\"ID\"].str.startswith(target_id)\n",
    "    if not mask.any():\n",
    "        log.warning(f\"No submission rows match target '{target_id}'. Skipping.\")\n",
    "        return\n",
    "\n",
    "    # sanity check: coords length must match number of rows for this target\n",
    "    num_rows = mask.sum()\n",
    "\n",
    "    for rank, (conf, coords, model_idx) in enumerate(best_samples, start=1):\n",
    "        if len(coords) != num_rows:\n",
    "            log.warning(\n",
    "                f\"Row/coord mismatch for target {target_id} (rank {rank}): \"\n",
    "                f\"{len(coords)} coords vs {num_rows} rows in template. Truncating to min.\"\n",
    "            )\n",
    "        limit = min(len(coords), num_rows)\n",
    "        xs = [coords[i][0] for i in range(limit)]\n",
    "        ys = [coords[i][1] for i in range(limit)]\n",
    "        zs = [coords[i][2] for i in range(limit)]\n",
    "\n",
    "        # Assign only the first `limit` matching rows to keep alignment\n",
    "        idxs = df_sub.index[mask][:limit]\n",
    "        df_sub.loc[idxs, f\"x_{rank}\"] = xs\n",
    "        df_sub.loc[idxs, f\"y_{rank}\"] = ys\n",
    "        df_sub.loc[idxs, f\"z_{rank}\"] = zs\n",
    "\n",
    "\n",
    "# main aggregation \n",
    "submission_df = pd.read_csv(SUBMISSION_TEMPLATE)\n",
    "target_dirs = sorted([p.name for p in PREDICTIONS_ROOT.iterdir() if p.is_dir()])\n",
    "\n",
    "log.info(f\"Found {len(target_dirs)} targets in {PREDICTIONS_ROOT}\")\n",
    "\n",
    "for target_id in target_dirs:\n",
    "    samples: list[tuple[float, list[tuple[float, float, float]], int]] = []\n",
    "    for idx in range(MAX_MODELS_PER_TARGET):\n",
    "        try:\n",
    "            coords, conf = load_coords_and_confidence(target_id, idx)\n",
    "            samples.append((conf, coords, idx))\n",
    "        except Exception as exc:\n",
    "            # many indices may not exist; keep it quiet unless truly unexpected\n",
    "            log.debug(f\"Skipping {target_id} model_{idx}: {exc}\")\n",
    "\n",
    "    if not samples:\n",
    "        log.warning(f\"No valid models found for {target_id}.\")\n",
    "        continue\n",
    "\n",
    "    # highest confidence first\n",
    "    samples.sort(key=lambda x: x[0], reverse=True)\n",
    "    top_samples = samples[:TOP_K]\n",
    "\n",
    "    fill_submission_for_target(submission_df, target_id, top_samples)\n",
    "    log.info(f\"{target_id}: used models {[s[2] for s in top_samples]} (by confidence)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a0246b9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:33:46.232077Z",
     "iopub.status.busy": "2025-05-22T03:33:46.231849Z",
     "iopub.status.idle": "2025-05-22T03:33:46.358310Z",
     "shell.execute_reply": "2025-05-22T03:33:46.357246Z"
    },
    "papermill": {
     "duration": 0.151317,
     "end_time": "2025-05-22T03:33:46.359706",
     "exception": false,
     "start_time": "2025-05-22T03:33:46.208389",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mboltz\u001b[0m/        \u001b[01;34minputs_prediction\u001b[0m/  \u001b[01;34moutputs_prediction\u001b[0m/\r\n",
      "inference.py  __notebook__.ipynb  submission.csv\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "352d7b68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:33:46.408843Z",
     "iopub.status.busy": "2025-05-22T03:33:46.408560Z",
     "iopub.status.idle": "2025-05-22T03:33:46.540885Z",
     "shell.execute_reply": "2025-05-22T03:33:46.539796Z"
    },
    "papermill": {
     "duration": 0.158081,
     "end_time": "2025-05-22T03:33:46.542224",
     "exception": false,
     "start_time": "2025-05-22T03:33:46.384143",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%rm -rf boltz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "afa00ccc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:33:46.590616Z",
     "iopub.status.busy": "2025-05-22T03:33:46.590301Z",
     "iopub.status.idle": "2025-05-22T03:33:46.714477Z",
     "shell.execute_reply": "2025-05-22T03:33:46.713529Z"
    },
    "papermill": {
     "duration": 0.149378,
     "end_time": "2025-05-22T03:33:46.715808",
     "exception": false,
     "start_time": "2025-05-22T03:33:46.566430",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%rm -rf inputs_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "740be233",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:33:46.763798Z",
     "iopub.status.busy": "2025-05-22T03:33:46.763525Z",
     "iopub.status.idle": "2025-05-22T03:33:46.905588Z",
     "shell.execute_reply": "2025-05-22T03:33:46.904515Z"
    },
    "papermill": {
     "duration": 0.167016,
     "end_time": "2025-05-22T03:33:46.907150",
     "exception": false,
     "start_time": "2025-05-22T03:33:46.740134",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%rm -rf outputs_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eae2a413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:33:46.955951Z",
     "iopub.status.busy": "2025-05-22T03:33:46.955645Z",
     "iopub.status.idle": "2025-05-22T03:33:47.079976Z",
     "shell.execute_reply": "2025-05-22T03:33:47.078867Z"
    },
    "papermill": {
     "duration": 0.150082,
     "end_time": "2025-05-22T03:33:47.081653",
     "exception": false,
     "start_time": "2025-05-22T03:33:46.931571",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%rm -rf inference.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f525f130",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:33:47.129251Z",
     "iopub.status.busy": "2025-05-22T03:33:47.128965Z",
     "iopub.status.idle": "2025-05-22T03:33:47.254787Z",
     "shell.execute_reply": "2025-05-22T03:33:47.253906Z"
    },
    "papermill": {
     "duration": 0.150423,
     "end_time": "2025-05-22T03:33:47.256189",
     "exception": false,
     "start_time": "2025-05-22T03:33:47.105766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__notebook__.ipynb  submission.csv\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04889455",
   "metadata": {
    "papermill": {
     "duration": 0.022086,
     "end_time": "2025-05-22T03:33:47.301972",
     "exception": false,
     "start_time": "2025-05-22T03:33:47.279886",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52fd2f1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-05-22T03:33:47.348653Z",
     "iopub.status.busy": "2025-05-22T03:33:47.348291Z",
     "iopub.status.idle": "2025-05-22T03:33:47.392096Z",
     "shell.execute_reply": "2025-05-22T03:33:47.391243Z"
    },
    "papermill": {
     "duration": 0.06876,
     "end_time": "2025-05-22T03:33:47.393370",
     "exception": false,
     "start_time": "2025-05-22T03:33:47.324610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>resname</th>\n",
       "      <th>resid</th>\n",
       "      <th>x_1</th>\n",
       "      <th>y_1</th>\n",
       "      <th>z_1</th>\n",
       "      <th>x_2</th>\n",
       "      <th>y_2</th>\n",
       "      <th>z_2</th>\n",
       "      <th>x_3</th>\n",
       "      <th>y_3</th>\n",
       "      <th>z_3</th>\n",
       "      <th>x_4</th>\n",
       "      <th>y_4</th>\n",
       "      <th>z_4</th>\n",
       "      <th>x_5</th>\n",
       "      <th>y_5</th>\n",
       "      <th>z_5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>R1107_1</td>\n",
       "      <td>G</td>\n",
       "      <td>1</td>\n",
       "      <td>3.70495</td>\n",
       "      <td>-14.33893</td>\n",
       "      <td>-10.09669</td>\n",
       "      <td>4.02854</td>\n",
       "      <td>-17.73680</td>\n",
       "      <td>17.98308</td>\n",
       "      <td>-9.57090</td>\n",
       "      <td>5.12235</td>\n",
       "      <td>16.47663</td>\n",
       "      <td>14.67717</td>\n",
       "      <td>-13.73870</td>\n",
       "      <td>0.36041</td>\n",
       "      <td>-18.78674</td>\n",
       "      <td>7.66877</td>\n",
       "      <td>-6.27028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>R1107_2</td>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1.14741</td>\n",
       "      <td>-11.06134</td>\n",
       "      <td>-13.74821</td>\n",
       "      <td>2.70712</td>\n",
       "      <td>-21.31407</td>\n",
       "      <td>14.04303</td>\n",
       "      <td>-5.63369</td>\n",
       "      <td>8.51553</td>\n",
       "      <td>14.91798</td>\n",
       "      <td>10.09968</td>\n",
       "      <td>-16.43514</td>\n",
       "      <td>1.82790</td>\n",
       "      <td>-17.50484</td>\n",
       "      <td>10.34362</td>\n",
       "      <td>-1.59239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>R1107_3</td>\n",
       "      <td>G</td>\n",
       "      <td>3</td>\n",
       "      <td>-2.14035</td>\n",
       "      <td>-6.70239</td>\n",
       "      <td>-15.06713</td>\n",
       "      <td>-1.01750</td>\n",
       "      <td>-24.00727</td>\n",
       "      <td>11.00196</td>\n",
       "      <td>-0.53064</td>\n",
       "      <td>10.03004</td>\n",
       "      <td>13.33584</td>\n",
       "      <td>5.27593</td>\n",
       "      <td>-16.88308</td>\n",
       "      <td>4.64238</td>\n",
       "      <td>-15.32987</td>\n",
       "      <td>10.87270</td>\n",
       "      <td>3.56209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>R1107_4</td>\n",
       "      <td>G</td>\n",
       "      <td>4</td>\n",
       "      <td>-2.17234</td>\n",
       "      <td>-0.60930</td>\n",
       "      <td>-13.42071</td>\n",
       "      <td>-6.05388</td>\n",
       "      <td>-24.44052</td>\n",
       "      <td>8.94807</td>\n",
       "      <td>4.41230</td>\n",
       "      <td>9.29037</td>\n",
       "      <td>10.91419</td>\n",
       "      <td>1.01392</td>\n",
       "      <td>-14.32377</td>\n",
       "      <td>6.91798</td>\n",
       "      <td>-11.68615</td>\n",
       "      <td>9.54526</td>\n",
       "      <td>7.53135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R1107_5</td>\n",
       "      <td>G</td>\n",
       "      <td>5</td>\n",
       "      <td>0.77151</td>\n",
       "      <td>3.77795</td>\n",
       "      <td>-11.44262</td>\n",
       "      <td>-10.94124</td>\n",
       "      <td>-22.26543</td>\n",
       "      <td>7.63880</td>\n",
       "      <td>7.53758</td>\n",
       "      <td>6.75297</td>\n",
       "      <td>7.00821</td>\n",
       "      <td>-1.47926</td>\n",
       "      <td>-9.50194</td>\n",
       "      <td>5.91292</td>\n",
       "      <td>-6.61575</td>\n",
       "      <td>7.48247</td>\n",
       "      <td>9.00864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>R1107_6</td>\n",
       "      <td>C</td>\n",
       "      <td>6</td>\n",
       "      <td>5.67863</td>\n",
       "      <td>5.70963</td>\n",
       "      <td>-10.11880</td>\n",
       "      <td>-14.21652</td>\n",
       "      <td>-17.94730</td>\n",
       "      <td>6.72871</td>\n",
       "      <td>7.51149</td>\n",
       "      <td>3.88782</td>\n",
       "      <td>2.32127</td>\n",
       "      <td>-2.03465</td>\n",
       "      <td>-5.31495</td>\n",
       "      <td>2.37080</td>\n",
       "      <td>-1.27673</td>\n",
       "      <td>6.21076</td>\n",
       "      <td>7.60576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>R1107_7</td>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>11.02761</td>\n",
       "      <td>5.55795</td>\n",
       "      <td>-9.97404</td>\n",
       "      <td>-15.23629</td>\n",
       "      <td>-12.76198</td>\n",
       "      <td>5.73029</td>\n",
       "      <td>3.95808</td>\n",
       "      <td>2.32277</td>\n",
       "      <td>-1.16555</td>\n",
       "      <td>-1.87518</td>\n",
       "      <td>-5.07159</td>\n",
       "      <td>-2.84111</td>\n",
       "      <td>2.58904</td>\n",
       "      <td>6.95155</td>\n",
       "      <td>4.03119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>R1107_8</td>\n",
       "      <td>A</td>\n",
       "      <td>8</td>\n",
       "      <td>18.04744</td>\n",
       "      <td>4.86127</td>\n",
       "      <td>-8.03881</td>\n",
       "      <td>-13.39502</td>\n",
       "      <td>-8.17929</td>\n",
       "      <td>4.32908</td>\n",
       "      <td>-1.08548</td>\n",
       "      <td>3.56857</td>\n",
       "      <td>-2.47697</td>\n",
       "      <td>0.02936</td>\n",
       "      <td>-0.74087</td>\n",
       "      <td>-5.05757</td>\n",
       "      <td>4.13797</td>\n",
       "      <td>9.39085</td>\n",
       "      <td>-0.29584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>R1107_9</td>\n",
       "      <td>C</td>\n",
       "      <td>9</td>\n",
       "      <td>15.15094</td>\n",
       "      <td>2.14722</td>\n",
       "      <td>-3.62010</td>\n",
       "      <td>-9.69963</td>\n",
       "      <td>-5.92144</td>\n",
       "      <td>1.72035</td>\n",
       "      <td>-6.74810</td>\n",
       "      <td>3.35136</td>\n",
       "      <td>-3.70763</td>\n",
       "      <td>2.87785</td>\n",
       "      <td>3.48328</td>\n",
       "      <td>-7.68874</td>\n",
       "      <td>5.36403</td>\n",
       "      <td>13.49620</td>\n",
       "      <td>-4.02454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>R1107_10</td>\n",
       "      <td>A</td>\n",
       "      <td>10</td>\n",
       "      <td>13.85003</td>\n",
       "      <td>1.55464</td>\n",
       "      <td>1.60036</td>\n",
       "      <td>-6.66339</td>\n",
       "      <td>-6.83633</td>\n",
       "      <td>-2.01346</td>\n",
       "      <td>-12.40604</td>\n",
       "      <td>3.41132</td>\n",
       "      <td>-6.09684</td>\n",
       "      <td>4.12825</td>\n",
       "      <td>6.77217</td>\n",
       "      <td>-11.98940</td>\n",
       "      <td>5.90802</td>\n",
       "      <td>11.55650</td>\n",
       "      <td>-11.28776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>R1107_11</td>\n",
       "      <td>G</td>\n",
       "      <td>11</td>\n",
       "      <td>13.76170</td>\n",
       "      <td>2.77160</td>\n",
       "      <td>7.07754</td>\n",
       "      <td>-3.25937</td>\n",
       "      <td>-8.63505</td>\n",
       "      <td>-6.13592</td>\n",
       "      <td>-16.23153</td>\n",
       "      <td>4.28809</td>\n",
       "      <td>-10.24368</td>\n",
       "      <td>3.45114</td>\n",
       "      <td>9.21480</td>\n",
       "      <td>-17.10964</td>\n",
       "      <td>6.09980</td>\n",
       "      <td>7.03496</td>\n",
       "      <td>-14.34282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>R1107_12</td>\n",
       "      <td>C</td>\n",
       "      <td>12</td>\n",
       "      <td>14.03916</td>\n",
       "      <td>6.64263</td>\n",
       "      <td>10.79315</td>\n",
       "      <td>-2.57439</td>\n",
       "      <td>-9.67683</td>\n",
       "      <td>-11.37816</td>\n",
       "      <td>-16.92887</td>\n",
       "      <td>6.12141</td>\n",
       "      <td>-15.20571</td>\n",
       "      <td>-0.08465</td>\n",
       "      <td>9.80804</td>\n",
       "      <td>-21.20053</td>\n",
       "      <td>8.98624</td>\n",
       "      <td>3.02049</td>\n",
       "      <td>-16.56145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>R1107_13</td>\n",
       "      <td>A</td>\n",
       "      <td>13</td>\n",
       "      <td>14.09841</td>\n",
       "      <td>11.80542</td>\n",
       "      <td>12.22491</td>\n",
       "      <td>-4.37134</td>\n",
       "      <td>-9.36260</td>\n",
       "      <td>-16.41496</td>\n",
       "      <td>-15.07407</td>\n",
       "      <td>8.20105</td>\n",
       "      <td>-19.68247</td>\n",
       "      <td>-4.98624</td>\n",
       "      <td>9.06454</td>\n",
       "      <td>-23.38624</td>\n",
       "      <td>13.58212</td>\n",
       "      <td>0.17927</td>\n",
       "      <td>-17.05048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>R1107_14</td>\n",
       "      <td>G</td>\n",
       "      <td>14</td>\n",
       "      <td>13.13366</td>\n",
       "      <td>17.08347</td>\n",
       "      <td>11.32751</td>\n",
       "      <td>-7.49165</td>\n",
       "      <td>-7.27011</td>\n",
       "      <td>-20.38389</td>\n",
       "      <td>-11.14968</td>\n",
       "      <td>9.44903</td>\n",
       "      <td>-23.07164</td>\n",
       "      <td>-10.24133</td>\n",
       "      <td>7.89587</td>\n",
       "      <td>-23.09298</td>\n",
       "      <td>18.54455</td>\n",
       "      <td>-1.48281</td>\n",
       "      <td>-15.49251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>R1107_15</td>\n",
       "      <td>A</td>\n",
       "      <td>15</td>\n",
       "      <td>10.83682</td>\n",
       "      <td>21.28741</td>\n",
       "      <td>8.64134</td>\n",
       "      <td>-10.79205</td>\n",
       "      <td>-3.34065</td>\n",
       "      <td>-22.43922</td>\n",
       "      <td>-6.08654</td>\n",
       "      <td>9.26172</td>\n",
       "      <td>-25.14195</td>\n",
       "      <td>-14.89991</td>\n",
       "      <td>6.79492</td>\n",
       "      <td>-20.53564</td>\n",
       "      <td>22.75579</td>\n",
       "      <td>-1.97737</td>\n",
       "      <td>-11.98648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>R1107_16</td>\n",
       "      <td>A</td>\n",
       "      <td>16</td>\n",
       "      <td>7.08935</td>\n",
       "      <td>23.38083</td>\n",
       "      <td>5.25865</td>\n",
       "      <td>-12.79272</td>\n",
       "      <td>1.80942</td>\n",
       "      <td>-22.20384</td>\n",
       "      <td>-1.21096</td>\n",
       "      <td>7.07176</td>\n",
       "      <td>-25.91674</td>\n",
       "      <td>-18.28533</td>\n",
       "      <td>6.53688</td>\n",
       "      <td>-16.46693</td>\n",
       "      <td>25.02120</td>\n",
       "      <td>-1.85778</td>\n",
       "      <td>-7.10229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>R1107_17</td>\n",
       "      <td>G</td>\n",
       "      <td>17</td>\n",
       "      <td>2.03754</td>\n",
       "      <td>22.70737</td>\n",
       "      <td>2.42324</td>\n",
       "      <td>-10.91559</td>\n",
       "      <td>7.16503</td>\n",
       "      <td>-19.47005</td>\n",
       "      <td>2.11405</td>\n",
       "      <td>2.95567</td>\n",
       "      <td>-25.70922</td>\n",
       "      <td>-19.71052</td>\n",
       "      <td>7.58689</td>\n",
       "      <td>-11.73200</td>\n",
       "      <td>24.05036</td>\n",
       "      <td>-1.49804</td>\n",
       "      <td>-2.00906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>R1107_18</td>\n",
       "      <td>C</td>\n",
       "      <td>18</td>\n",
       "      <td>-2.62571</td>\n",
       "      <td>22.91192</td>\n",
       "      <td>-1.69789</td>\n",
       "      <td>-8.50203</td>\n",
       "      <td>12.67538</td>\n",
       "      <td>-17.39941</td>\n",
       "      <td>2.52018</td>\n",
       "      <td>-2.08630</td>\n",
       "      <td>-26.34174</td>\n",
       "      <td>-22.27316</td>\n",
       "      <td>3.35184</td>\n",
       "      <td>-6.86913</td>\n",
       "      <td>22.20407</td>\n",
       "      <td>0.66911</td>\n",
       "      <td>3.46976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>R1107_19</td>\n",
       "      <td>G</td>\n",
       "      <td>19</td>\n",
       "      <td>-7.93466</td>\n",
       "      <td>23.23404</td>\n",
       "      <td>-3.33375</td>\n",
       "      <td>-4.43290</td>\n",
       "      <td>16.44123</td>\n",
       "      <td>-17.37261</td>\n",
       "      <td>7.79466</td>\n",
       "      <td>-8.30031</td>\n",
       "      <td>-29.85664</td>\n",
       "      <td>-25.61321</td>\n",
       "      <td>2.11543</td>\n",
       "      <td>-2.31353</td>\n",
       "      <td>21.13966</td>\n",
       "      <td>1.47932</td>\n",
       "      <td>9.04116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>R1107_20</td>\n",
       "      <td>U</td>\n",
       "      <td>20</td>\n",
       "      <td>-12.99744</td>\n",
       "      <td>23.07394</td>\n",
       "      <td>-1.60450</td>\n",
       "      <td>0.51082</td>\n",
       "      <td>17.45146</td>\n",
       "      <td>-19.29619</td>\n",
       "      <td>10.41531</td>\n",
       "      <td>-11.13112</td>\n",
       "      <td>-25.89460</td>\n",
       "      <td>-27.34402</td>\n",
       "      <td>4.98465</td>\n",
       "      <td>2.12766</td>\n",
       "      <td>19.90500</td>\n",
       "      <td>-1.13830</td>\n",
       "      <td>13.47337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          ID resname  resid       x_1       y_1       z_1       x_2       y_2  \\\n",
       "0    R1107_1       G      1   3.70495 -14.33893 -10.09669   4.02854 -17.73680   \n",
       "1    R1107_2       G      2   1.14741 -11.06134 -13.74821   2.70712 -21.31407   \n",
       "2    R1107_3       G      3  -2.14035  -6.70239 -15.06713  -1.01750 -24.00727   \n",
       "3    R1107_4       G      4  -2.17234  -0.60930 -13.42071  -6.05388 -24.44052   \n",
       "4    R1107_5       G      5   0.77151   3.77795 -11.44262 -10.94124 -22.26543   \n",
       "5    R1107_6       C      6   5.67863   5.70963 -10.11880 -14.21652 -17.94730   \n",
       "6    R1107_7       C      7  11.02761   5.55795  -9.97404 -15.23629 -12.76198   \n",
       "7    R1107_8       A      8  18.04744   4.86127  -8.03881 -13.39502  -8.17929   \n",
       "8    R1107_9       C      9  15.15094   2.14722  -3.62010  -9.69963  -5.92144   \n",
       "9   R1107_10       A     10  13.85003   1.55464   1.60036  -6.66339  -6.83633   \n",
       "10  R1107_11       G     11  13.76170   2.77160   7.07754  -3.25937  -8.63505   \n",
       "11  R1107_12       C     12  14.03916   6.64263  10.79315  -2.57439  -9.67683   \n",
       "12  R1107_13       A     13  14.09841  11.80542  12.22491  -4.37134  -9.36260   \n",
       "13  R1107_14       G     14  13.13366  17.08347  11.32751  -7.49165  -7.27011   \n",
       "14  R1107_15       A     15  10.83682  21.28741   8.64134 -10.79205  -3.34065   \n",
       "15  R1107_16       A     16   7.08935  23.38083   5.25865 -12.79272   1.80942   \n",
       "16  R1107_17       G     17   2.03754  22.70737   2.42324 -10.91559   7.16503   \n",
       "17  R1107_18       C     18  -2.62571  22.91192  -1.69789  -8.50203  12.67538   \n",
       "18  R1107_19       G     19  -7.93466  23.23404  -3.33375  -4.43290  16.44123   \n",
       "19  R1107_20       U     20 -12.99744  23.07394  -1.60450   0.51082  17.45146   \n",
       "\n",
       "         z_2       x_3       y_3       z_3       x_4       y_4       z_4  \\\n",
       "0   17.98308  -9.57090   5.12235  16.47663  14.67717 -13.73870   0.36041   \n",
       "1   14.04303  -5.63369   8.51553  14.91798  10.09968 -16.43514   1.82790   \n",
       "2   11.00196  -0.53064  10.03004  13.33584   5.27593 -16.88308   4.64238   \n",
       "3    8.94807   4.41230   9.29037  10.91419   1.01392 -14.32377   6.91798   \n",
       "4    7.63880   7.53758   6.75297   7.00821  -1.47926  -9.50194   5.91292   \n",
       "5    6.72871   7.51149   3.88782   2.32127  -2.03465  -5.31495   2.37080   \n",
       "6    5.73029   3.95808   2.32277  -1.16555  -1.87518  -5.07159  -2.84111   \n",
       "7    4.32908  -1.08548   3.56857  -2.47697   0.02936  -0.74087  -5.05757   \n",
       "8    1.72035  -6.74810   3.35136  -3.70763   2.87785   3.48328  -7.68874   \n",
       "9   -2.01346 -12.40604   3.41132  -6.09684   4.12825   6.77217 -11.98940   \n",
       "10  -6.13592 -16.23153   4.28809 -10.24368   3.45114   9.21480 -17.10964   \n",
       "11 -11.37816 -16.92887   6.12141 -15.20571  -0.08465   9.80804 -21.20053   \n",
       "12 -16.41496 -15.07407   8.20105 -19.68247  -4.98624   9.06454 -23.38624   \n",
       "13 -20.38389 -11.14968   9.44903 -23.07164 -10.24133   7.89587 -23.09298   \n",
       "14 -22.43922  -6.08654   9.26172 -25.14195 -14.89991   6.79492 -20.53564   \n",
       "15 -22.20384  -1.21096   7.07176 -25.91674 -18.28533   6.53688 -16.46693   \n",
       "16 -19.47005   2.11405   2.95567 -25.70922 -19.71052   7.58689 -11.73200   \n",
       "17 -17.39941   2.52018  -2.08630 -26.34174 -22.27316   3.35184  -6.86913   \n",
       "18 -17.37261   7.79466  -8.30031 -29.85664 -25.61321   2.11543  -2.31353   \n",
       "19 -19.29619  10.41531 -11.13112 -25.89460 -27.34402   4.98465   2.12766   \n",
       "\n",
       "         x_5       y_5       z_5  \n",
       "0  -18.78674   7.66877  -6.27028  \n",
       "1  -17.50484  10.34362  -1.59239  \n",
       "2  -15.32987  10.87270   3.56209  \n",
       "3  -11.68615   9.54526   7.53135  \n",
       "4   -6.61575   7.48247   9.00864  \n",
       "5   -1.27673   6.21076   7.60576  \n",
       "6    2.58904   6.95155   4.03119  \n",
       "7    4.13797   9.39085  -0.29584  \n",
       "8    5.36403  13.49620  -4.02454  \n",
       "9    5.90802  11.55650 -11.28776  \n",
       "10   6.09980   7.03496 -14.34282  \n",
       "11   8.98624   3.02049 -16.56145  \n",
       "12  13.58212   0.17927 -17.05048  \n",
       "13  18.54455  -1.48281 -15.49251  \n",
       "14  22.75579  -1.97737 -11.98648  \n",
       "15  25.02120  -1.85778  -7.10229  \n",
       "16  24.05036  -1.49804  -2.00906  \n",
       "17  22.20407   0.66911   3.46976  \n",
       "18  21.13966   1.47932   9.04116  \n",
       "19  19.90500  -1.13830  13.47337  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save\n",
    "submission_df.to_csv(SUBMISSION_OUT, index=False)\n",
    "log.info(f\"Wrote submission to {SUBMISSION_OUT.resolve()}\")\n",
    "submission_df = pd.read_csv(\"submission.csv\")\n",
    "submission_df.head(20)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 12276181,
     "sourceId": 87793,
     "sourceType": "competition"
    },
    {
     "datasetId": 2975803,
     "sourceId": 5123458,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6760509,
     "sourceId": 10880419,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6785143,
     "sourceId": 10923077,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6791615,
     "sourceId": 11695366,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30919,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 1916.605522,
   "end_time": "2025-05-22T03:33:48.534873",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-05-22T03:01:51.929351",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
